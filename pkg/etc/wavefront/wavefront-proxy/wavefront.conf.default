#
# Wavefront proxy configuration file
#
#   Typically in /etc/wavefront/wavefront-proxy/wavefront.conf
#
########################################################################################################################
# Wavefront API endpoint URL. Usually the same as the URL of your Wavefront instance, with an `api`
# suffix -- or Wavefront provides the URL.
server=https://try.wavefront.com/api/

# The hostname will be used to identify the internal proxy statistics around point rates, JVM info, etc.
# We strongly recommend setting this to a name that is unique among your entire infrastructure, to make this
# proxy easy to identify. This hostname does not need to correspond to any actual hostname or DNS entry; it's merely
# a string that we pass with the internal stats and ~proxy.* metrics.
#hostname=my.proxy.host.com

# The Token is any valid API token for an account that has *Proxy Management* permissions. To get to the token:
# 1. Click the gear icon at the top right in the Wavefront UI.
# 2. Click your account name (usually your email)
# 3. Click *API access*.
#token=

####################################################### INPUTS #########################################################
# Comma-separated list of ports to listen on for Wavefront formatted data (Default: 2878)
pushListenerPorts=2878
## Maximum line length for received points in plaintext format on Wavefront/OpenTSDB/Graphite ports. Default: 32KB
#pushListenerMaxReceivedLength=32768
## Maximum request size (in bytes) for incoming HTTP requests on Wavefront/OpenTSDB/Graphite ports. Default: 16MB
#pushListenerHttpBufferSize=16777216

## Delta counter pre-aggregation settings.
## Comma-separated list of ports to listen on for Wavefront-formatted delta counters. Helps reduce
## outbound point rate by pre-aggregating delta counters at proxy. Default: none
#deltaCountersAggregationListenerPorts=12878
## Interval between flushing aggregating delta counters to Wavefront. Defaults to 30 seconds.
#deltaCountersAggregationIntervalSeconds=60

## Graphite input settings.
## If you enable either `graphitePorts` or `picklePorts`, make sure to uncomment and set `graphiteFormat` as well.
## Comma-separated list of ports to listen on for collectd/Graphite formatted data (Default: none)
#graphitePorts=2003
## Comma-separated list of ports to listen on for Graphite pickle formatted data (from carbon-relay) (Default: none)
#picklePorts=2004
## Which fields (1-based) should we extract and concatenate (with dots) as the hostname?
#graphiteFormat=2
## Which characters should be replaced by dots in the hostname, after extraction? (Default: _)
#graphiteDelimiters=_
## Comma-separated list of fields (metric segments) to remove (1-based). This is an optional setting. (Default: none)
#graphiteFieldsToRemove=3,4,5

## OTLP/OpenTelemetry input settings.
## Comma-separated list of ports to listen on for OTLP formatted data over gRPC (Default: none)
#otlpGrpcListenerPorts=4317
## Comma-separated list of ports to listen on for OTLP formatted data over HTTP (Default: none)
#otlpHttpListenerPorts=4318

## DDI/Relay endpoint: in environments where no direct outbound connections to Wavefront servers are possible, you can
## use another Wavefront proxy that has outbound access to act as a relay and forward all the data received on that
## endpoint (from direct data ingestion clients and/or other proxies) to Wavefront servers.
## This setting is a comma-separated list of ports. (Default: none)
#pushRelayListenerPorts=2978
## If true, aggregate histogram distributions received on the relay port.
## Please refer to histogram settings section below for more configuration options. Default: false
#pushRelayHistogramAggregator=false

## Comma-separated list of ports to listen on for OpenTSDB formatted data (Default: none)
#opentsdbPorts=4242

## Comma-separated list of ports to listen on for HTTP JSON formatted data (Default: none)
#jsonListenerPorts=3878

## Comma-separated list of ports to listen on for HTTP collectd write_http data (Default: none)
#writeHttpJsonListenerPorts=4878

################################################# DATA PREPROCESSING ###################################################
## Path to the optional config file with preprocessor rules (advanced regEx replacements and allow/block lists)
#preprocessorConfigFile=/etc/wavefront/wavefront-proxy/preprocessor_rules.yaml

## When using the Wavefront or TSDB data formats, the proxy will automatically look for a tag named
## source= or host= (preferring source=) and treat that as the source/host within Wavefront.
## customSourceTags is a comma-separated, ordered list of additional tag keys to use if neither
## source= or host= is present
#customSourceTags=fqdn, hostname

## The prefix should either be left undefined, or can be any  prefix you want
## prepended to all data points coming through this proxy (such as `production`).
#prefix=production

## Regex pattern (Java) that input lines must match to be accepted. Use preprocessor rules for finer control.
#allow=^(production|stage).*
## Regex pattern (Java) that input lines must NOT match to be accepted. Use preprocessor rules for finer control.
#block=^(qa|development|test).*

## This setting defines the cut-off point for what is considered a valid timestamp for back-dated points.
## Default (and recommended) value is 8760 (1 year), so all the data points from more than 1 year ago will be rejected.
#dataBackfillCutoffHours=8760
## This setting defines the cut-off point for what is considered a valid timestamp for pre-dated points.
## Default (and recommended) value is 24 (1 day), so all the data points from more than 1 day in future will be rejected.
#dataPrefillCutoffHours=24

################################################## ADVANCED SETTINGS ###################################################
## Number of threads that flush data to the server. If not defined in wavefront.conf it defaults to
## the number of available vCPUs (min 4; max 16). Setting this value too large will result in sending
## batches that are too small to the server and wasting connections. This setting is per listening port.
#flushThreads=4
## Max points per single flush. Default: 40000.
#pushFlushMaxPoints=40000
## Max histograms per single flush. Default: 10000.
#pushFlushMaxHistograms=10000
## Max spans per single flush. Default: 5000.
#pushFlushMaxSpans=5000
## Max span logs per single flush. Default: 1000.
#pushFlushMaxSpanLogs=1000

## Milliseconds between flushes to the Wavefront servers. Typically 1000.
#pushFlushInterval=1000

## Limit outbound points per second rate at the proxy. Default: do not throttle
#pushRateLimit=20000
## Limit outbound histograms per second rate at the proxy. Default: do not throttle
#pushRateLimitHistograms=2000
## Limit outbound spans per second rate at the proxy. Default: do not throttle
#pushRateLimitSpans=1000
## Limit outbound span logs per second rate at the proxy. Default: do not throttle
#pushRateLimitSpanLogs=1000

## Max number of burst seconds to allow when rate limiting to smooth out uneven traffic.
## Set to 1 when doing data backfills. Default: 10
#pushRateLimitMaxBurstSeconds=10

## Location of buffer.* files for saving failed transmissions for retry. Default: /var/spool/wavefront-proxy/buffer
#buffer=/var/spool/wavefront-proxy/buffer
## Buffer file partition size, in MB. Setting this value too low may reduce the efficiency of disk
## space utilization, while setting this value too high will allocate disk space in larger
## increments. Default: 128
#bufferShardSize=128
## Use single-file buffer (legacy functionality). Default: false
#disableBufferSharding=false

## For exponential backoff when retry threads are throttled, the base (a in a^b) in seconds.  Default 2.0
#retryBackoffBaseSeconds=2.0
## Whether to split the push batch size when the push is rejected by Wavefront due to rate limit.  Default false.
#splitPushWhenRateLimited=false

## The following settings are used to connect to Wavefront servers through a HTTP proxy:
#proxyHost=localhost
#proxyPort=8080
## Optional: if http proxy requires authentication
#proxyUser=proxy_user
#proxyPassword=proxy_password
## HTTP proxies may implement a security policy to only allow traffic with particular User-Agent header values.
## When set, overrides User-Agent in request headers for outbound HTTP requests.
#httpUserAgent=WavefrontProxy

## HTTP client settings
## Control whether metrics traffic from the proxy to the Wavefront endpoint is gzip-compressed. Default: true
#gzipCompression=true
## If gzipCompression is enabled, sets compression level (1-9). Higher compression levels slightly reduce
## the volume of traffic between the proxy and Wavefront, but use more CPU. Default: 4
#gzipCompressionLevel=4
## Connect timeout (in milliseconds). Default: 5000 (5s)
#httpConnectTimeout=5000
## Socket timeout (in milliseconds). Default: 10000 (10s)
#httpRequestTimeout=10000
## Max number of total connections to keep open (Default: 200)
#httpMaxConnTotal=100
## Max connections per route to keep open (Default: 100)
#httpMaxConnPerRoute=100
## Number of times to retry http requests before queueing, set to 0 to disable (default: 3)
#httpAutoRetries=3

## Close idle inbound connections after specified time in seconds. Default: 300 (5 minutes)
#listenerIdleConnectionTimeout=300
## When receiving Wavefront-formatted data without source/host specified, use remote IP address as
## source instead of trying to resolve the DNS name. Default false.
#disableRdnsLookup=true
## The following setting enables SO_LINGER on listening ports with the specified linger time in seconds (Default: off)
#soLingerTime=0

## Max number of points that can stay in memory buffers before spooling to disk. Defaults to 16 * pushFlushMaxPoints,
## minimum allowed size: pushFlushMaxPoints. Setting this value lower than default reduces memory usage but will force
## the proxy to spool to disk more frequently if you have points arriving at the proxy in short bursts.
#pushMemoryBufferLimit=640000

## If there are blocked points, a small sampling of them can be written into the main log file.
## This setting how many lines to print to the log every 10 seconds. Typically 5.
#pushBlockedSamples=5
## When logging blocked points is enabled (see https://docs.wavefront.com/proxies_configuring.html#blocked-point-log
## for more details), by default all blocked points/histograms/spans etc are logged into the same `RawBlockedPoints`
## logger. Settings below allow finer control over these loggers:
## Logger name for blocked points. Default: RawBlockedPoints.
#blockedPointsLoggerName=RawBlockedPoints
## Logger name for blocked histograms. Default: RawBlockedPoints.
#blockedHistogramsLoggerName=RawBlockedPoints
## Logger name for blocked spans. Default: RawBlockedPoints.
#blockedSpansLoggerName=RawBlockedPoints

## Discard all received data (debug/performance test mode). If enabled, you will lose received data! Default: false
#useNoopSender=false

## Settings for incoming HTTP request authentication. Authentication is done by a token, proxy is looking for
## tokens in the querystring ("token=" and "api_key=" parameters) and in request headers ("X-AUTH-TOKEN: ",
## "Authorization: Bearer", "Authorization: " headers). TCP streams are disabled when authentication is turned on.
## Allowed authentication methods: NONE, STATIC_TOKEN, HTTP_GET, OAUTH2. Default: NONE
## - NONE: All requests are considered valid
## - STATIC_TOKEN: Compare incoming token with the value of authStaticToken setting.
## - OAUTH2: Validate all tokens against a RFC7662-compliant token introspection endpoint.
## - HTTP_GET: Validate all tokens against a specific URL. Use {{token}} placeholder in the URL to pass the token
##             in question to the endpoint. Use of https is strongly recommended for security reasons. The endpoint
##             must return any 2xx status for valid tokens, any other response code is considered a fail.
#authMethod=NONE
## URL for the token introspection endpoint used to validate tokens for incoming HTTP requests.
## Required when authMethod is OAUTH2 or HTTP_GET
#authTokenIntrospectionServiceUrl=https://auth.acme.corp/api/token/{{token}}/validate
## Optional credentials for use with the token introspection endpoint if it requires authentication.
#authTokenIntrospectionAuthorizationHeader=Authorization: Bearer <token>
## Cache TTL (in seconds) for token validation results (re-authenticate when expired). Default: 600 seconds
#authResponseRefreshInterval=600
## Maximum allowed cache TTL (in seconds) for token validation results when token introspection service is
## unavailable. Default: 86400 seconds (1 day)
#authResponseMaxTtl=86400
## Static token that is considered valid for all incoming HTTP requests. Required when authMethod = STATIC_TOKEN.
#authStaticToken=token1234abcd

## Enables intelligent traffic shaping based on received rate over last 5 minutes. Default: disabled
#trafficShaping=false
## Sets the width (in seconds) for the sliding time window which would be used to calculate received
## traffic rate. Default: 600 (10 minutes)
#trafficShapingWindowSeconds=600
## Sets the headroom multiplier to use for traffic shaping when there's backlog. Default: 1.15 (15% headroom)
#trafficShapingHeadroom=1.15

## Enables CORS for specified comma-delimited list of listening ports. Default: none (CORS disabled)
#corsEnabledPorts=2879
## Allowed origin for CORS requests, or '*' to allow everything. Default: none
#corsOrigin=*
## Allow 'null' origin for CORS requests. Default: false
#corsAllowNullOrigin=false

## Enables TLS for specified listening ports (comma-separated list). Use '*' to secure all ports. Defaut: none (TLS disabled)
#tlsPorts=4443
## TLS certificate path to use for securing all the ports. X.509 certificate chain file in PEM format.
#privateCertPath=/etc/wavefront/wavefront-proxy/cert.pem
## TLS private key path to use for securing all the ports. PKCS#8 private key file in PEM format.
#privateKeyPath=/etc/wavefront/wavefront-proxy/private_key.pem

########################################### MANAGED HEALTHCHECK ENDPOINT ###############################################
## Comma-delimited list of ports to function as standalone healthchecks. May be used independently of
## httpHealthCheckAllPorts parameter. Default: none
#httpHealthCheckPorts=8880
## When true, all listeners that support HTTP protocol also respond to healthcheck requests. May be
## used independently of httpHealthCheckPorts parameter. Default: false
#httpHealthCheckAllPorts=true
## Healthcheck's path, for example, '/health'. Default: '/'
#httpHealthCheckPath=/status
## Optional Content-Type to use in healthcheck response, for example, 'application/json'. Default: none
#httpHealthCheckResponseContentType=text/plain
## HTTP status code for 'pass' health checks. Default: 200
#httpHealthCheckPassStatusCode=200
## Optional response body to return with 'pass' health checks. Default: none
#httpHealthCheckPassResponseBody=good to go!
## HTTP status code for 'fail' health checks. Default: 503
#httpHealthCheckFailStatusCode=503
## Optional response body to return with 'fail' health checks. Default: none
#httpHealthCheckFailResponseBody=try again later...
## Enables admin port to control healthcheck status per port. Default: none
#adminApiListenerPort=8888
## Remote IPs must match this regex to access admin API
#adminApiRemoteIpAllowRegex=^.*$

############################################# LOGS TO METRICS SETTINGS #################################################
## Port on which to listen for FileBeat data (Lumberjack protocol). Default: none
#filebeatPort=5044
## Port on which to listen for raw logs data (TCP and HTTP). Default: none
#rawLogsPort=5045
## Maximum line length for received raw logs (Default: 4096)
#rawLogsMaxReceivedLength=4096
## Maximum allowed request size (in bytes) for incoming HTTP requests with raw logs (Default: 16MB)
#rawLogsHttpBufferSize=16777216
## Location of the `logsingestion.yaml` configuration file
#logsIngestionConfigFile=/etc/wavefront/wavefront-proxy/logsingestion.yaml

########################################### DISTRIBUTED TRACING SETTINGS ###############################################
## Comma-separated list of ports to listen on for spans in Wavefront format. Defaults to none.
#traceListenerPorts=30000
## Maximum line length for received spans and span logs (Default: 1MB)
#traceListenerMaxReceivedLength=1048576
## Maximum allowed request size (in bytes) for incoming HTTP requests on tracing ports (Default: 16MB)
#traceListenerHttpBufferSize=16777216

## Comma-separated list of ports to listen on for spans from SDKs that send raw data. Unlike
## `traceListenerPorts` setting, also derives RED metrics based on received spans. Defaults to none.
#customTracingListenerPorts=30001
## Custom application name for spans received on customTracingListenerPorts. Defaults to defaultApp.
#customTracingApplicationName=defaultApp
## Custom service name for spans received on customTracingListenerPorts. Defaults to defaultService.
#customTracingServiceName=defaultService

## Comma-separated list of ports on which to listen on for Jaeger Thrift formatted data over TChannel protocol. Defaults to none.
#traceJaegerListenerPorts=14267
## Comma-separated list of ports on which to listen on for Jaeger Thrift formatted data over HTTP. Defaults to none.
#traceJaegerHttpListenerPorts=14268
## Comma-separated list of ports on which to listen on for Jaeger Protobuf formatted data over gRPC. Defaults to none.
#traceJaegerGrpcListenerPorts=14250
## Custom application name for traces received on Jaeger's traceJaegerListenerPorts.
#traceJaegerApplicationName=Jaeger
## Comma-separated list of ports on which to listen on for Zipkin trace data over HTTP. Defaults to none.
## Recommended value is 9411, which is the port Zipkin's server listens on and is the default configuration in Istio.
#traceZipkinListenerPorts=9411
## Custom application name for traces received on Zipkin's traceZipkinListenerPorts.
#traceZipkinApplicationName=Zipkin
## Comma-separated list of additional custom tag keys to include along as metric tags for the derived
## RED (Request, Error, Duration) metrics. Applicable to Jaeger and Zipkin integration only.
#traceDerivedCustomTagKeys=tenant, env, location

## The following settings are used to configure trace data sampling:
## The rate for traces to be sampled. Can be from 0.0 to 1.0. Defaults to 1.0
#traceSamplingRate=1.0
## The minimum duration threshold (in milliseconds) for the spans to be sampled.
## Spans above the given duration are reported. Defaults to 0 (include everything).
#traceSamplingDuration=0

########################################## HISTOGRAM ACCUMULATION SETTINGS #############################################
## Histograms can be ingested in Wavefront scalar and distribution format. For scalar samples ports can be specified for
## minute, hour and day granularity. Granularity for the distribution format is encoded inline. Before using any of
## these settings, reach out to Wavefront Support to ensure your account is enabled for native Histogram support and
## to optimize the settings for your specific use case.

## Accumulation parameters
## Directory for persisting proxy state, must be writable.
#histogramStateDirectory=/var/spool/wavefront-proxy
## Interval to write back accumulation changes to disk in milliseconds (only applicable when memory cache is enabled).
#histogramAccumulatorResolveInterval=5000
## Interval to check for histograms ready to be sent to Wavefront, in milliseconds.
#histogramAccumulatorFlushInterval=10000
## Max number of histograms to send to Wavefront in one flush (Default: no limit)
#histogramAccumulatorFlushMaxBatchSize=4000
## Maximum line length for received histogram data (Default: 65536)
#histogramMaxReceivedLength=65536
## Maximum allowed request size (in bytes) for incoming HTTP requests on histogram ports (Default: 16MB)
#histogramHttpBufferSize=16777216

## Wavefront format, minute aggregation:
## Comma-separated list of ports to listen on.
#histogramMinuteListenerPorts=40001
## Time-to-live in seconds for a minute granularity accumulation on the proxy (before the intermediary is shipped to WF).
#histogramMinuteFlushSecs=70
## Bounds the number of centroids per histogram. Must be between 20 and 1000, default: 32
#histogramMinuteCompression=32
## Expected upper bound of concurrent accumulations. Should be approximately the number of timeseries * 2 (use a higher
## multiplier if out-of-order points more than 1 minute apart are expected). Setting this value too high will cause
## excessive disk space usage, setting this value too low may cause severe performance issues.
#histogramMinuteAccumulatorSize=1000
## Enabling memory cache reduces I/O load with fewer time series and higher frequency data (more than 1 point per
## second per time series). Default: false
#histogramMinuteMemoryCache=false
## Whether to persist accumulation state. When true, all histograms are written to disk immediately if memory cache is
## disabled, or every histogramAccumulatorResolveInterval seconds if memory cache is enabled.
## If accumulator is not persisted, up to histogramMinuteFlushSecs seconds worth of histograms may be lost on proxy shutdown.
#histogramMinuteAccumulatorPersisted=false

## Wavefront format, hour aggregation:
## Comma-separated list of ports to listen on.
#histogramHourListenerPorts=40002
## Time-to-live in seconds for an hour granularity accumulation on the proxy (before the intermediary is shipped to WF).
#histogramHourFlushSecs=4200
## Bounds the number of centroids per histogram. Must be between 20 and 1000, default: 32
#histogramHourCompression=32
## Expected upper bound of concurrent accumulations. Should be approximately the number of timeseries * 2 (use a higher
## multiplier if out-of-order points more than 1 hour apart are expected). Setting this value too high will cause
## excessive disk space usage, setting this value too low may cause severe performance issues.
#histogramHourAccumulatorSize=100000
## Enabling memory cache reduces I/O load with fewer time series and higher frequency data (more than 1 point per
## second per time series). Default: false
#histogramHourMemoryCache=true
## Whether to persist accumulation state. When true, all histograms are written to disk immediately if memory cache is
## disabled, or every `histogramAccumulatorResolveInterval` seconds if memory cache is enabled.
## If accumulator is not persisted, up to `histogramHourFlushSecs` seconds worth of histograms may be lost on proxy shutdown.
#histogramHourAccumulatorPersisted=true

## Wavefront format, day aggregation:
## Comma-separated list of ports to listen on.
#histogramDayListenerPorts=40003
## Time-to-live in seconds for a day granularity accumulation on the proxy (before the intermediary is shipped to WF).
#histogramDayFlushSecs=18000
## Bounds the number of centroids per histogram. Must be between 20 and 1000, default: 32
#histogramDayCompression=32
## Expected upper bound of concurrent accumulations. Should be approximately the number of timeseries * 2 (use a higher
## multiplier if out-of-order points more than 1 day apart are expected). Setting this value too high will cause
## excessive disk space usage, setting this value too low may cause severe performance issues.
#histogramDayAccumulatorSize=100000
## Enabling memory cache reduces I/O load with fewer time series and higher frequency data (more than 1 point per
## second per time series). Default: false
#histogramDayMemoryCache=false
## Whether to persist accumulation state. When true, all histograms are written to disk immediately if memory cache is
## disabled, or every `histogramAccumulatorResolveInterval` seconds if memory cache is enabled.
## If accumulator is not persisted, up to `histogramDayFlushSecs` seconds worth of histograms may be lost on proxy shutdown.
#histogramDayAccumulatorPersisted=true

## Distribution format:
## Comma-separated list of ports to listen on.
#histogramDistListenerPorts=40000
## Time-to-live in seconds for a distribution accumulation on the proxy (before the intermediary is shipped to WF).
#histogramDistFlushSecs=70
## Bounds the number of centroids per histogram. Must be between 20 and 1000, default: 32
#histogramDistCompression=32
## Expected upper bound of concurrent accumulations. Should be approximately the number of timeseries * 2 (use a higher
## multiplier if out-of-order points more than 1 bin apart are expected). Setting this value too high will cause
## excessive disk space usage, setting this value too low may cause severe performance issues.
#histogramDistAccumulatorSize=100000
## Enabling memory cache reduces I/O load with fewer time series and higher frequency data (more than 1 point per
## second per time series). Default: false
#histogramDistMemoryCache=false
## Whether to persist accumulation state. When true, all histograms are written to disk immediately if memory cache is
## disabled, or every histogramAccumulatorResolveInterval seconds if memory cache is enabled.
## If accumulator is not persisted, up to histogramDistFlushSecs seconds worth of histograms may be lost on proxy shutdown.
#histogramDistAccumulatorPersisted=true

## Histogram accumulation for relay ports (only applicable if pushRelayHistogramAggregator is true):
## Time-to-live in seconds for the accumulator (before the intermediary is shipped to WF). Default: 70
#pushRelayHistogramAggregatorFlushSecs=70
## Bounds the number of centroids per histogram. Must be between 20 and 1000, default: 32
#pushRelayHistogramAggregatorCompression=32
## Expected upper bound of concurrent accumulations. Should be approximately the number of timeseries * 2 (use a higher
## multiplier if out-of-order points more than 1 bin apart are expected). Setting this value too high will cause
## excessive disk space usage, setting this value too low may cause severe performance issues.
#pushRelayHistogramAggregatorAccumulatorSize=1000000
